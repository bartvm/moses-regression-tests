# MERT optimized configuration
# decoder /home/s0565741/workspace/github/hh/bin/moses
# BLEU 0.14175 on dev /home/s0565741/workspace/experiment/europarl/fr-en-small/tuning/input.lc.2
# We were before running iteration 6
# finished Thu Dec 19 15:08:19 GMT 2013
### MOSES CONFIG FILE ###
#########################

# input factors
[input-factors]
0

# mapping steps
[mapping]
0 T 0

[distortion-limit]
6

# feature functions
[feature]
UnknownWordPenalty
WordPenalty
PhrasePenalty
PhraseDictionaryBinary name=TranslationModel0 table-limit=20 num-features=4 path=${TEST_PATH}/phrase-table.0-0,1.1.1 input-factor=0 output-factor=0,1 
LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=${TEST_PATH}/reordering-table.2.0-0.wbe-msd-bidirectional-fe 
Distortion
KENLM lazyken=1 name=LM0 factor=0 path=${TEST_PATH}/europarl.binlm.1 order=5
IRSTLM name=LM1 factor=1 path=${TEST_PATH}/europarl_pos.binlm.2 order=7

# dense weights for feature functions

[v]
0
[weight]

LexicalReordering0= 0.116336 0.04106 0.0552949 0.0944314 0.074487 0.0855557
Distortion0= 0.0912773
LM0= 0.0999473
LM1= -0.0111935
WordPenalty0= 0.0301454
PhrasePenalty0= -0.0106492
TranslationModel0= 0.00673786 0.0956166 0.117016 0.0702517
